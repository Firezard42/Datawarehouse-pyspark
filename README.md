# ğŸ“Š Mini Data Warehouse com PySpark e Arquitetura MedalhÃ£o

Este projeto tem como objetivo construir um mini **Data Warehouse** utilizando **PySpark**, baseado na **Arquitetura MedalhÃ£o (Medallion Architecture)**, com dados pÃºblicos da Receita Federal.

O fluxo segue as camadas tradicionais da arquitetura:

- **Landing (LND)**: Armazenamento dos dados brutos diretamente dos arquivos CSV extraÃ­dos.
- **Raw (RAW)**: EstruturaÃ§Ã£o dos dados com schemas definidos em PySpark.
- **Trusted (TRS)**: AplicaÃ§Ã£o de regras de consistÃªncia, enriquecimento (enrichment), e junÃ§Ãµes entre fatos e dimensÃµes.
- **AnÃ¡lise (Notebook Final)**: Consultas e visualizaÃ§Ãµes com o Delta Lake.

---

## ğŸ—‚ï¸ Dados utilizados

Os dados foram obtidos do portal oficial da Receita Federal na seÃ§Ã£o de [Dados Abertos CNPJ](https://dadosabertos.rfb.gov.br/CNPJ). Os arquivos utilizados incluem:

- **Empresas**
- **Estabelecimentos**
- **Natureza JurÃ­dica**
- **CNAE (ClassificaÃ§Ã£o Nacional de Atividades EconÃ´micas)**
- **Simples Nacional**
- **MunicÃ­pios (da Receita Federal, nÃ£o do IBGE)**

> âš ï¸ **ObservaÃ§Ã£o**: Os dados complementares necessÃ¡rios para este projeto â€” como Natureza JurÃ­dica, CNAE, Simples Nacional, MunicÃ­pios da Receita, entre outros â€” **nÃ£o estÃ£o disponÃ­veis via API pÃºblica**. No entanto, podem ser baixados diretamente como arquivos `.CSV` no portal da Receita Federal.

---

## âš™ï¸ EstratÃ©gia de Coleta

- **Sem uso de paginaÃ§Ã£o**:\
  O processo de ingestÃ£o **nÃ£o utilizou paginaÃ§Ã£o via API**.\
  Isso ocorreu pois **os dados foram obtidos em arquivos **``** contendo arquivos **``** separados por partes**, como `Empresas0.zip`, `Empresas1.zip` etc.

- **Processamento arquivo por arquivo**:\
  Cada um desses arquivos foi baixado, extraÃ­do, convertido e carregado manualmente em formato `.csv`.\
  Por isso, **nÃ£o hÃ¡ um Ãºnico notebook de extraÃ§Ã£o genÃ©rica com paginaÃ§Ã£o ou cursor**.\
  Cada CSV foi processado separadamente na camada de **Landing (LND)** e convertido para **Raw** com schema definido no PySpark.

---

## ğŸ§± Camadas da Arquitetura

### ğŸ”¹ Landing (LND)

Armazenamento inicial dos arquivos CSV convertidos de `.zip`, sem transformaÃ§Ã£o.\
Exemplo: `empresas_2025-07-17.csv`, `simples_2025-07-17.csv`.

### ğŸ”¹ Raw (RAW)

Leitura dos CSVs com `pyspark.read.csv()` aplicando `schema` e gravando no formato Delta Lake.

### ğŸ”¹ Trusted (TRS)

TransformaÃ§Ãµes aplicadas:

- Regras de consistÃªncia: remoÃ§Ã£o de `null`, `""`, ou registros incompletos
- Joins entre empresas e:
  - Natureza JurÃ­dica
  - CNAE
  - Simples Nacional
  - MunicÃ­pio (com enriquecimento da `UF`)
- RenomeaÃ§Ã£o e limpeza de colunas

### ğŸ”¹ AnÃ¡lise

Consulta e visualizaÃ§Ã£o de dados agregados:

- Quantidade de empresas por UF
- Empresas optantes pelo Simples Nacional
- DistribuiÃ§Ã£o por natureza jurÃ­dica
- Versionamento via `DESCRIBE HISTORY`

---

## ğŸ›† Formato e Versionamento

- Todos os dados das camadas **RAW** e **TRUSTED** foram salvos no formato **Delta Lake**.
- Foram feitas **duas versÃµes** das tabelas Delta para demonstrar o versionamento e uso de `overwrite`.

Exemplo de comando usado:

```python
spark.sql("""
    DESCRIBE HISTORY delta.`C:/caminho/para/tabela`
""").show(truncate=False)
```

---

## âœ… Status do Projeto

| Etapa                            | Status |
| -------------------------------- | ------ |
| Coleta dos dados (manual)        | âœ…      |
| ConversÃ£o e salvamento em LND    | âœ…      |
| PreparaÃ§Ã£o com schema na RAW     | âœ…      |
| Regras de qualidade (Trusted)    | âœ…      |
| Enriquecimento de dados          | âœ…      |
| Joins entre fato e dimensÃµes     | âœ…      |
| Escrita em Delta + versionamento | âœ…      |
| AnÃ¡lise e visualizaÃ§Ãµes          | âœ…      |

---

## ğŸ› ï¸ Tecnologias e Bibliotecas

- **PySpark** 4.00
- **Delta Lake**
- **Jupyter Notebooks**
- **Requests**
- **findspark**

---

## ğŸ§  Conceitos Abordados

- Arquitetura de dados (Medallion)
- Tabelas Fato e DimensÃ£o
- OperaÃ§Ãµes de Join
- Qualidade de dados (regras de consistÃªncia)
- Versionamento com Delta Lake

---

## ğŸ“ OrganizaÃ§Ã£o de Pastas

```
IBGE_PROJETO/
ğŸ—‚ï¸ data/
   â”œï¸ LND/         # Dados brutos (.csv)
   â”œï¸ RAW/         # Dados estruturados em Delta
   â””ï¸ TRS/         # Dados confiÃ¡veis com joins e enrichments
ğŸ—‹ notebooks/
   â”œï¸ 01_coleta_dados.ipynb
   â”œï¸ 02_preparacao_raw.ipynb
   â”œï¸ 03_transformacao_trusted.ipynb
   â””ï¸ 04_analise_resultados.ipynb
```

---

## âœï¸ Autor

Este projeto foi desenvolvido por Ivaldo JanuÃ¡rio dos Santos Neto (Firezard42) como parte do treinamento prÃ¡tico da ResidÃªncia em TIC da UFAL/EASY em parceria com o SENAI/AL, com foco em Engenharia de Dados.

O objetivo desta atividade Ã© nivelar o conhecimento tÃ©cnico dos residentes, preparando-os para o desenvolvimento do projeto real que serÃ¡ realizado nas etapas seguintes da residÃªncia.

---