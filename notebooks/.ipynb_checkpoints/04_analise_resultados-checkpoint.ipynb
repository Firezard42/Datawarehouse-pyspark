{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c748cc0-e849-44a2-8566-0389ae765de9",
   "metadata": {},
   "source": [
    "                                    TODOS IMPORT NECESSÁRIOS PARA RODAR PYSPARK + DELTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f394cdc-72ef-4c15-b79b-1f4ea18c104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffbede5-7987-4e57-a106-0c8595f168ae",
   "metadata": {},
   "source": [
    "- Aqui configura o Hadoop localmente, essencial para que o Spark funcione corretamente no Windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd418e58-c13e-491e-90b6-6df47dd9b3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HADOOP_HOME\"] = \"C:\\\\hadoop\"\n",
    "os.environ[\"HADOOP_COMMON_HOME\"] = \"C:\\\\hadoop\"\n",
    "os.environ[\"HADOOP_HDFS_HOME\"] = \"C:\\\\hadoop\"\n",
    "os.environ[\"HADOOP_TMP_DIR\"] = \"C:\\\\hadoop\\\\tmp\"\n",
    "os.environ[\"PATH\"] = f\"{os.environ['PATH']};C:\\\\hadoop\\\\bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31dfaca1-4519-49d4-a7c3-897e891f79f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Garante que a pasta tmp exista para o Hadoop não dar erro ao iniciar.\n",
    "if not os.path.exists(\"C:\\\\hadoop\\\\tmp\"):\n",
    "    os.makedirs(\"C:\\\\hadoop\\\\tmp\")\n",
    "\n",
    "# Configurações essenciais para Windows\n",
    "os.environ[\"HADOOP_USER_NAME\"] = os.getlogin()  # Usuário atual do Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3149e697-823f-4497-ad2a-6efd7413229a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from delta import configure_spark_with_delta_pip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953e8812-da2a-445d-be19-26749a0f060a",
   "metadata": {},
   "source": [
    "- Adiciona os JARs do Hadoop à variável de ambiente SPARK_CLASSPATH para que o Spark consiga usá-los."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1985af0e-bb17-4bd6-a419-f5498a209a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkFiles\n",
    "spark_jars = \":\".join([\n",
    "    \"C:\\\\hadoop\\\\share\\\\hadoop\\\\common\\\\*.jar\",\n",
    "    \"C:\\\\hadoop\\\\share\\\\hadoop\\\\common\\\\lib\\\\*.jar\"\n",
    "])\n",
    "os.environ[\"SPARK_CLASSPATH\"] = spark_jars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e1a236-7d6f-435f-a29c-dd51c67318bc",
   "metadata": {},
   "source": [
    "                                CRIAÇÃO DE SESSÃO COM CONFIGURAÇÃO NECESSÁRIO PARA O FUNCIONANDO DO DELTA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4969a10f-e8c1-4d5b-91c9-63fe86adc7d5",
   "metadata": {},
   "source": [
    "- Configura a sessão com suporte a Delta Lake, manipulação local de arquivos (LocalFileSystem) e aumento da memória do driver para 4 GB (melhora performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66ac6cda-4ad9-4dd2-926a-66bae8af092d",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = SparkSession.builder \\\n",
    "    .appName('DW_analise') \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.hadoop.fs.file.impl\", \"org.apache.hadoop.fs.LocalFileSystem\") \\\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"-Dio.netty.tryReflectionSetAccessible=true\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"file:///C:/temp/spark-warehouse\") \\\n",
    "    .config(\"spark.network.timeout\", \"600s\") \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"file:///\") \\\n",
    "    .config(\"spark.delta.logStore.class\", \"org.apache.spark.sql.delta.storage.HDFSLogStore\")\\\n",
    "    .config(\"spark.driver.memory\", \"4g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea739eb3-8af7-4499-b8e8-84ed7088074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = configure_spark_with_delta_pip(builder).getOrCreate() #Cria e inicia a sessão do Spark com o Delta configurado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd635ba2-6064-4fcc-92a7-ccb74fba2502",
   "metadata": {},
   "source": [
    "                                           CARREGANDO O TRUSTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6103af71-5f43-488b-99cd-b581da35ff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trusted = spark.read.format('delta').load(r'C:\\Users\\ResTIC16\\Documents\\IBGE_PROJETO\\datawarehouse_ibge\\data\\TRS\\empresas2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c108a2-bc26-4c87-a526-d7a736b4c288",
   "metadata": {},
   "source": [
    "                                           NÚMERO TOTAL DE EMPRESAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b28d448-4017-47de-b8c7-454cd3381920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de empresas: 5000\n"
     ]
    }
   ],
   "source": [
    "print(\"Total de empresas:\", df_trusted.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f885644-b047-4711-b2ac-2238c2a694fa",
   "metadata": {},
   "source": [
    "                                         NÚMERO DE EMPRESA POR ESTADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11f788b2-80e7-43e6-94c4-62b0ec3e208c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|uf  |count|\n",
      "+----+-----+\n",
      "|NULL|4459 |\n",
      "|SP  |131  |\n",
      "|MG  |39   |\n",
      "|EX  |34   |\n",
      "|RN  |34   |\n",
      "|RS  |33   |\n",
      "|RJ  |32   |\n",
      "|PR  |30   |\n",
      "|PB  |26   |\n",
      "|SC  |24   |\n",
      "|BA  |23   |\n",
      "|PE  |20   |\n",
      "|CE  |17   |\n",
      "|PA  |16   |\n",
      "|GO  |13   |\n",
      "|MA  |12   |\n",
      "|ES  |10   |\n",
      "|DF  |9    |\n",
      "|MT  |8    |\n",
      "|MS  |7    |\n",
      "+----+-----+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df_trusted.groupBy(\"uf\").count().orderBy(\"count\", ascending=False).show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bc391e-e7c3-4225-878a-22c4bb0ee9e9",
   "metadata": {},
   "source": [
    "                                        TIPOS MAIS COMUNS DE NATUREZA JURÍDICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53a5c91f-fe3a-4836-8f68-1a391ec61c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------+-----+\n",
      "|descricao                                     |count|\n",
      "+----------------------------------------------+-----+\n",
      "|Sociedade Empresária Limitada                 |1739 |\n",
      "|Empresário (Individual)                       |1522 |\n",
      "|Candidato a Cargo Político Eletivo            |577  |\n",
      "|Fundação ou Associação Domiciliada no Exterior|337  |\n",
      "|Associação Privada                            |295  |\n",
      "|Produtor Rural (Pessoa Física)                |172  |\n",
      "|Sociedade Simples Limitada                    |166  |\n",
      "|Condomínio Edilício                           |51   |\n",
      "|Empresa Domiciliada no Exterior               |20   |\n",
      "|Sociedade Simples Pura                        |17   |\n",
      "+----------------------------------------------+-----+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "df_trusted.groupBy(\"descricao\").count().orderBy(\"count\", ascending=False).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b673ae0e-f8ed-4056-82a8-d53f1bb2f210",
   "metadata": {},
   "source": [
    "                                        EMPRESAS OPTANTES PELA SIMPLES NACIONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10b71d9b-40dd-4593-8dc7-48eee421bffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|  uf|count|\n",
      "+----+-----+\n",
      "|NULL|  524|\n",
      "|  SP|   20|\n",
      "|  MG|    6|\n",
      "|  RS|    5|\n",
      "|  RJ|    4|\n",
      "|  BA|    3|\n",
      "|  PR|    3|\n",
      "|  GO|    2|\n",
      "|  ES|    2|\n",
      "|  CE|    2|\n",
      "|  MA|    2|\n",
      "|  SC|    1|\n",
      "|  RO|    1|\n",
      "|  MS|    1|\n",
      "|  SE|    1|\n",
      "|  PE|    1|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_trusted.filter(col(\"opcao_simples\") == \"S\").groupBy(\"uf\").count().orderBy(\"count\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c582802-9b1d-4225-be40-23e6c4f9dc39",
   "metadata": {},
   "source": [
    "                                                VERSÕES DO DELTA LAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "398b9c7a-6c7d-46a7-9484-1cf0347f5fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+---------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|version|timestamp              |userId|userName|operation|operationParameters                   |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                                                                                     |userMetadata|engineInfo                         |\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+---------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|1      |2025-07-22 12:46:55.606|NULL  |NULL    |WRITE    |{mode -> Overwrite, partitionBy -> []}|NULL|NULL    |NULL     |0          |Serializable  |false        |{numFiles -> 1, numRemovedFiles -> 20, numRemovedBytes -> 148863038, numOutputRows -> 5000, numOutputBytes -> 184358}|NULL        |Apache-Spark/4.0.0 Delta-Lake/4.0.0|\n",
      "|0      |2025-07-22 10:45:52.684|NULL  |NULL    |WRITE    |{mode -> Overwrite, partitionBy -> []}|NULL|NULL    |NULL     |NULL       |Serializable  |false        |{numFiles -> 20, numRemovedFiles -> 0, numRemovedBytes -> 0, numOutputRows -> 4679055, numOutputBytes -> 148863038}  |NULL        |Apache-Spark/4.0.0 Delta-Lake/4.0.0|\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+---------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    DESCRIBE HISTORY delta.`C:/Users/ResTIC16/Documents/IBGE_PROJETO/datawarehouse_ibge/data/TRS/empresas2`\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bc7de4-a0aa-4095-ad2e-bfc2b5dc1cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
